{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13b3d2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/office/miniforge3/envs/ml1/lib/python3.12/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/office/miniforge3/envs/ml1/lib/python3.12/site-packages/pytorch_lightning/utilities/model_summary/model_summary.py:231: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n",
      "\n",
      "  | Name           | Type               | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | flatten        | Flatten            | 0      | train\n",
      "1 | fc             | Sequential         | 101 K  | train\n",
      "2 | criterion      | CrossEntropyLoss   | 0      | train\n",
      "3 | train_accuracy | MulticlassAccuracy | 0      | train\n",
      "4 | val_accuracy   | MulticlassAccuracy | 0      | train\n",
      "--------------------------------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.407     Total estimated model params size (MB)\n",
      "8         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/office/miniforge3/envs/ml1/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/office/miniforge3/envs/ml1/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 71.56it/s, v_num=0, train_loss_step=1.240, train_acc_step=1.000, val_loss=2.310, val_acc=0.100, train_loss_epoch=1.270, train_acc_epoch=1.000] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 60.81it/s, v_num=0, train_loss_step=1.240, train_acc_step=1.000, val_loss=2.310, val_acc=0.100, train_loss_epoch=1.270, train_acc_epoch=1.000]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import Accuracy\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "# Enable Tensor Core optimization\n",
    "torch.set_float32_matmul_precision('medium')  # or 'high' for even more speed\n",
    "\n",
    "# Create TensorBoard logger\n",
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"my_model\")\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample, label\n",
    "\n",
    "class EnhancedLightningModel(pl.LightningModule):\n",
    "    def __init__(self, learning_rate=0.001):\n",
    "        super().__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Model architecture\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "        \n",
    "        # Loss function\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Metrics\n",
    "        self.train_accuracy = Accuracy(task='multiclass', num_classes=10)\n",
    "        self.val_accuracy = Accuracy(task='multiclass', num_classes=10)\n",
    "        \n",
    "        # Save hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"Training step\"\"\"\n",
    "        inputs, labels = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        acc = self.train_accuracy(preds, labels)\n",
    "        \n",
    "        # Log metrics\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_acc', acc, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"Validation step\"\"\"\n",
    "        inputs, labels = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        acc = self.val_accuracy(preds, labels)\n",
    "        \n",
    "        # Log metrics\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('val_acc', acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Configure optimizer\"\"\"\n",
    "        return optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "# Data preparation\n",
    "X_train = torch.rand(80, 1, 28, 28)  # 80 samples for training\n",
    "y_train = torch.randint(0, 10, (80,))\n",
    "\n",
    "X_val = torch.rand(20, 1, 28, 28)    # 20 samples for validation\n",
    "y_val = torch.randint(0, 10, (20,))\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CustomDataset(X_train, y_train, transform=transforms.Normalize((0.5,), (0.5,)))\n",
    "val_dataset = CustomDataset(X_val, y_val, transform=transforms.Normalize((0.5,), (0.5,)))\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize model and trainer\n",
    "model = EnhancedLightningModel(learning_rate=0.001)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=5,\n",
    "    accelerator='gpu',\n",
    "    devices=1,  # Use 1 GPU explicitly\n",
    "    precision='16-mixed',  # Mixed precision for speed\n",
    "    logger=logger,\n",
    "    log_every_n_steps=1,\n",
    "    enable_progress_bar=True,\n",
    "    enable_model_summary=True\n",
    ")\n",
    "\n",
    "# Train the model with validation\n",
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5aafd7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5db6d08c57189618\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5db6d08c57189618\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed317bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
